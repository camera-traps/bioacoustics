---
title: "acoustic_to_camtrapdp"
author: 
- "Sanne Govaert"
- "Julia Wiel"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(here)
library(dplyr)
library(tidyr)
library(frictionless)
library(camtrapdp)
library(lubridate)
```

```{r}
data_raw <- read.csv(here::here("data", "raw", "sound_of_norway_subsample.csv"))
```

# Create resources

## Inspect data

```{r}
(unique_values_per_column <-
  data_raw %>%
  dplyr::summarise(dplyr::across(dplyr::everything(), ~ dplyr::n_distinct(.))) %>%
  tidyr::pivot_longer(dplyr::everything(), names_to = "column", values_to = "n_unique"))
```

## Add information to dataset

```{r}
# Calculate eventEnd
data <-
  data_raw %>% 
  dplyr::mutate(
    detected_time_parsed = lubridate::ymd_hms(.data$detected_time, tz = "UTC"),
    eventEnd = .data$detected_time_parsed + .data$end_secs,
    eventEnd_iso = format(.data$eventEnd, format = "%Y-%m-%dT%H:%M:%OSZ", tz = "UTC")
  )

# Add scientificName
taxonomy <- 
  read.delim2(
    file = here::here("data", "raw","Bird names_english latin norsk.txt"), 
    sep = "\t", 
    header = TRUE
    ) %>% 
  dplyr::distinct() # Remove duplicates
data <- dplyr::left_join(data, taxonomy, dplyr::join_by(tags == EnglishName))

# Deployment start and end based on first and last detection for each site
deployments_raw <- data %>%
  group_by(site) %>%
  dplyr::mutate(
    deploymentStart = min(detected_time_parsed),
    deploymentEnd = max(detected_time_parsed)
    ) %>%
  dplyr::select(
    site, latitude, longitude, deploymentStart, deploymentEnd, recorder
    ) %>% 
  dplyr::distinct()
```

## Create deployments resource

```{r}
deployments <-
  deployments_raw %>% 
  dplyr::mutate(
    deploymentID = .data$site, # Required
    locationID = NULL,
    locationName = .data$site,
    latitude = .data$latitude, # Required
    longitude = .data$longitude, # Required
    coordinateUncertainty = NULL,
    deploymentStart = .data$deploymentStart, # Required
    deploymentEnd = .data$deploymentEnd, # Required
    setupBy = NULL,
    deviveID = .data$recorder,
    deviceModel = "Bugg v2022" ,
    deviceDelay = NULL,
    deviceHeight = "1.5",
    deviceDepth = NULL,
    deviceTilt = NULL,
    deviceHeading = NULL,
    dutyCycle = NULL,
    detectionDistance = NULL,
    timestampIssues = NULL,
    devicePlatform = "pole",
    baitUse = NULL,
    featureType = NULL,
    habitat = NULL,
    deploymentGroups = NULL,
    deploymentTags = NULL,
    deploymentComments = NULL,
    .keep = "none"
  ) %>% 
  dplyr::arrange(deploymentID)
```

## Create media resource

```{r}
#TODO: check duplicates in media
media <-
  data %>% 
  dplyr::mutate(
    mediaID = .data$audio_id, # Required
    deploymentID = .data$site, # Required
    captureMethod = "dutyCycle",
    timestamp = .data$detected_time, # Required
    filePath = .data$audio_link,# Required
    filePublic = FALSE, # Required
    fileName = NULL,
    fileMediatype = NULL, # Required # MP3 format (VBR0 using FFMPEG’s LAME  codec) not in https://www.iana.org/assignments/media-types/audio/mpeg
    samplingFrequency = "44100",
    bitDepth = "16",
    gain = NULL,
    channels = "1",
    duration = "300", # MediaDuration http://rs.tdwg.org/ac/terms/mediaDuration
    exifData = NULL,
    favorite = NULL,
    mediaComments = NULL,
    .keep = "none"
  ) %>% 
  dplyr::arrange(mediaID)
```

## Create observations resource

```{r}
observations <-
  data %>% 
  dplyr::mutate(
    observationID = .data$id, # Required
    deploymentID = .data$site, # Required
    mediaID = .data$audio_id,
    eventID = NA, # Necessary to use read_camtrapdp(), see https://github.com/inbo/camtrapdp/issues/162
    eventStart = .data$detected_time, # Required
    eventEnd = .data$eventEnd_iso, # Required
    observationLevel = "interval", # Required
    observationType = "animal", # Required 
    deviceSetupType = NULL,
    scientificName = .data$ScientificName,  # Required
    count = NULL,
    lifeStage = NULL,
    sex = NULL,
    behavior = NULL,
    individualID = NULL,
    individualPositionRadius = NULL,
    individualPositionAngle = NULL,
    individualSpeed = NULL,
    bboxX = NULL,
    bboxY = NULL,
    bboxWidth = NULL,
    bboxHeight = NULL,
    frequencyLow = NULL,
    frequencyHigh = NULL,
    classificationMethod = "machine",
    classifiedBy = .data$analysis,
    classificationTimestamp = "2023-06-23T12:23:00Z",
    classificationProbability = .data$confidence,
    observationTags = .data$tags,
    observationComments = NULL,
    .keep = "none"
  ) %>% 
  dplyr::arrange(observationID)
```

# Create data package

```{r}
acoustic <-
  frictionless::create_package() %>%
  add_resource(resource_name = "deployments", data = deployments) %>%
  add_resource(resource_name = "media", data = media) %>%
  add_resource(resource_name = "observations", data = observations) %>%
  append(c(
    name = "camtrap-dp-acoustic-example-dataset", # Required
    profile = "https://raw.githubusercontent.com/tdwg/camtrap-dp/1.0.1/camtrap-dp-profile.json", # Required (incorrect, hack to use read_camtrapdp())
    id = NULL,
    created = format(Sys.time(), "%Y-%m-%dT%H:%M:%SZ", tz = "UTC"), # Required
    title = "The Sound of Norway: bird detections",
    description = NULL,
    version = "1.0",
    keywords = c("acoustic", "birds", "passive acoustic monitoring"),
    image = NULL,
    homepage = NULL,
    sources = NULL,
    bibliographicCitation = "Bick, I. Avery, Vegar Bakkestuen, Benjamin Cretois, Ben Hillier, John A. Kålås, Marius Pedersen, Kiran Raja, et al. ‘National-Scale Acoustic Monitoring of Avian Biodiversity and Phenology’. Ecology, 24 May 2024. https://doi.org/10.1101/2024.05.21.595242",
    coordinatePrecision = NULL,
    spatial = NULL, # Required, but keep this empty, this comes later
    temporal = NULL, # Required, but keep this empty, this comes later
    taxonomic = NULL, # Required, but keep this empty, this comes later
    relatedIdentifiers = NULL,
    references = NULL
  )) %>%
  frictionless::create_package()

acoustic$contributors <- list( # Required
  list(
    title = "Julia Wiel",
    email = "julia.wiel@nina.no",
    path = "https://orcid.org/0009-0009-7224-3953",
    role = "contributor",
    organization = "Norwegian Institute for Nature Research (NINA)"
  ),
  list(
    title = "Benjamin Cretois",
    email = "benjamin.cretois@nina.no",
    path = "https://orcid.org/0000-0001-8668-3321",
    role = "rightsHolder",
    organization = "Norwegian Institute for Nature Research (NINA)"
  ),
  list(
    title = "Carolyn Rosten",
    email = "carolyn.rosten@nina.no",
    path = "https://orcid.org/0000-0002-1117-444X",
    role = "rightsHolder",
    organization = "Norwegian Institute for Nature Research (NINA)"
  ),
  list(
    title = "Sarab Sethi",
    email = "sarab.sethi@imperial.ac.uk",
    path = "https://orcid.org/0000-0002-5939-0432",
    role = "principalInvestigator",
    organization = "Imperial College London"
  ),
  list(
    title = "I. Avery Bick",
    email = "i.avery.bick@gmail.com",
    path = "https://orcid.org/0000-0002-8007-9649",
    role = "principalInvestigator",
    organization = "Norwegian Institute for Nature Research (NINA)"
  )
)

acoustic$licenses <- list(
  list(
    name = "CC0-1.0",
    scope = "data" # Required
  ),
  list(
    path = "http://creativecommons.org/licenses/by/4.0/",
    scope = "media" # Required
  )
)

acoustic$project <- list( # Required
  # id = "",
  title = "The Sound of Norway", # Required
  # acronym = "",
  description = "The Sound of Norway project monitors ecosystems across the nation with real- time recording devices. Using machine learning to automatically classify bird vocalisations, we can simultaneously track the distribution and migration patterns of many species on vast scales and over long time-periods.",
  protocolType = list(c("acoustic")), # Required
  samplingDesign = "systematicRandom", # Required
  path = "https://thesoundofnorway.com/",
  captureMethod = list(c("continuous")), # Required | Bug, see https://github.com/frictionlessdata/frictionless-r/issues/276
  individualAnimals = FALSE, # Required
  observationLevel = list(c("media")) # Required | Bug, see https://github.com/frictionlessdata/frictionless-r/issues/276
)
```

## Create taxonomy

```{r}
map_taxonomy <- function(taxonomy) {
  list(
    scientificName = taxonomy$ScientificName,
    vernacularNames = list(
      eng = taxonomy$EnglishName
      # nor = taxonomy$NorwegianName # Gives error in read_camtrapdp() | lexical error: invalid bytes in UTF8 string
      )
  )
}
```

```{r}
taxonomy_list <- apply(taxonomy, 1, as.list)
acoustic$taxonomic <- purrr::map(taxonomy_list, map_taxonomy)
```

# Write Data Package

```{r}
frictionless::write_package(acoustic, here::here("data", "interim", "sound_of_norway"))
```

# Read with camtrapdp

This automatically updates the spatial, temporal and taxonomic coverage in the metadata, based on the data.

```{r}
acoustic_dp <- camtrapdp::read_camtrapdp(here::here("data", "interim", "sound_of_norway", "datapackage.json"))
```

# Write Camtrap DP
```{r}
camtrapdp::write_camtrapdp(acoustic_dp, here::here("data", "processed", "sound_of_norway"))
```
