---
title: "acoustic_to_camtrapdp"
author: "Sanne Govaert and Julia Wiel"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#I made a BIIIGGGGG change
library(here)
library(dplyr)
library(tidyr)
library(frictionless)
library(lubridate)
library(camtrapdp)
```


```{r}
data_raw <- read.csv(here::here("data", "raw", "birdnet_lite_detections-proj_sound-of-norway-yr2complete.csv"))
data <- data_raw[1:5000,]
```

# Create resources

## Inspect data

```{r}
(unique_values_per_column <-
  data %>%
  summarise(across(everything(), ~ n_distinct(.))) %>%
  pivot_longer(everything(), names_to = "column", values_to = "n_unique"))
```

## Add information in dataset
```{r}
# eventEnd
data$detected_time_parsed <- ymd_hms(data$detected_time, tz = "UTC")
data$eventEnd <- data$detected_time_parsed + data$end_secs
data$eventEnd_iso <- format(data$eventEnd, format = "%Y-%m-%dT%H:%M:%OSZ", tz = "UTC")

# scientificName
taxonomy <- read.delim2(file = here::here("data", "raw","Bird names_english latin norsk.txt"), sep = "\t", header = TRUE)
data <- merge(data, taxonomy, by.x = "tags", by.y = "EnglishName")

# Deployment start and end based on first and last detection for each site
deployments_raw <- data %>%
  group_by(site) %>%
  dplyr::mutate(
    deploymentStart = min(detected_time_parsed),
    deploymentEnd = max(detected_time_parsed)
    ) %>%
  dplyr::select(
    site, latitude, longitude, deploymentStart, deploymentEnd, recorder
    ) %>% 
  dplyr::distinct()
```


## Create deployments resource

```{r}
deployments <-
  deployments_raw %>% 
  dplyr::mutate(
    deploymentID = .data$site, # Required
    locationID = NULL,
    locationName = .data$site,
    latitude = .data$latitude, # Required
    longitude = .data$longitude, # Required
    coordinateUncertainty = NULL,
    deploymentStart = .data$deploymentStart, # Required
    deploymentEnd = .data$deploymentEnd, # Required
    setupBy = NULL,
    deviveID = .data$recorder,
    deviceModel = "Bugg v2022" ,
    deviceDelay = NULL,
    deviceHeight = "1.5",
    deviceDepth = NULL,
    deviceTilt = NULL,
    deviceHeading = NULL,
    dutyCycle = NULL,
    detectionDistance = NULL,
    timestampIssues = NULL,
    devicePlatform = "pole",
    baitUse = NULL,
    featureType = NULL,
    habitat = NULL,
    deploymentGroups = NULL,
    deploymentTags = NULL,
    deploymentComments = NULL,
    .keep = "none"
  )
```

## Create media resource

```{r}
#TODO: check duplicates in media
media <-
  data %>% 
  dplyr::mutate(
    medidaID = .data$audio_id, # Required
    deploymentID = .data$site, # Required
    captureMethod = "dutyCycle", #Where to we explain that it's continuous?
    timestamp = .data$detected_time, # Required
    filePath = .data$audio_link,# Required
    filePublic = FALSE, # Required
    fileName = NULL,
    fileMediatype = NULL, # Required #MP3 format (VBR0 using FFMPEG’s LAME  codec) not in https://www.iana.org/assignments/media-types/audio/mpeg
    samplingFrequency = "44100",
    bitDepth = "16",
    gain = NULL,
    channels = "1",
    duration = "300", # I used mediaDuration http://rs.tdwg.org/ac/terms/mediaDuration
    exifData = NULL,
    favorite = NULL,
    mediaComments = NULL,
    .keep = "none"
  )
```

## Create observations resource

```{r}
observations <-
  data %>% 
  dplyr::mutate(
    observationID = .data$id, # Required
    deploymentID = .data$site, # Required
    mediaID = .data$audio_id,
    eventID = .data$id, # Necessary to use read_camtrapdp(), see https://github.com/inbo/camtrapdp/issues/162
    eventStart = .data$detected_time, # Required
    eventEnd = .data$eventEnd_iso, # Required
    observationLevel = "interval", # Required
    observationType = "animal", # Required #or "bird" to be specific
    deviceSetupType = NULL,
    scientificName = .data$ScientificName,  # Required
    count = NULL,
    lifeStage = NULL,
    sex = NULL,
    behavior = NULL,
    individualID = NULL,
    individualPositionRadius = NULL,
    individualPositionAngle = NULL,
    individualSpeed = NULL,
    bboxX = NULL,
    bboxY = NULL,
    bboxWidth = NULL,
    bboxHeight = NULL,
    frequencyLow = NULL,
    frequencyHigh = NULL,
    classificationMethod = "machine",
    classifiedBy = .data$analysis,
    classificationTimestamp = "2023-06-23T12:23:00Z", #I made it up based on the file system
    classificationProbability = .data$confidence,
    observationTags = .data$tags,
    observationComments = NULL,
    .keep = "none"
  )
```

# Create data package

```{r}
acoustic <-
  frictionless::create_package() %>%
  add_resource(resource_name = "deployments", data = deployments) %>%
  add_resource(resource_name = "media", data = media) %>%
  add_resource(resource_name = "observations", data = observations) %>%
  append(c(
    name = "camtrap-dp-acoustic-example-dataset", # Required
    path = NULL, # Required, but keep this empty for now
    profile = "https://raw.githubusercontent.com/tdwg/camtrap-dp/1.0.1/camtrap-dp-profile.json", # Required (hack to use read_camtrapdp())
    schema = NULL, # Required, but keep this empty for now
    id = NULL,
    created = format(Sys.time(), "%Y-%M-%dT%H:%M:%SZ", tz = "UTC"), # Required
    title = "The Sound of Norway: bird detections",
    description = NULL,
    version = "1.0",
    keywords = c("acoustic", "birds", "passive acoustic monitoring"),
    image = NULL,
    homepage = NULL,
    sources = NULL,
    bibliographicCitation = "Bick, I. Avery, Vegar Bakkestuen, Benjamin Cretois, Ben Hillier, John A. Kålås, Marius Pedersen, Kiran Raja, et al. ‘National-Scale Acoustic Monitoring of Avian Biodiversity and Phenology’. Ecology, 24 May 2024. https://doi.org/10.1101/2024.05.21.595242",
    coordinatePrecision = NULL,
    spatial = NULL, # Required, but keep this empty, this comes later
    temporal = NULL, # Required, but keep this empty, this comes later
    taxonomic = NULL, # Required, but keep this empty, this comes later
    relatedIdentifiers = NULL,
    references = NULL
  )) %>%
  frictionless::create_package()

acoustic$contributors <- list( # Required
  list(
    title = "Julia Wiel",
    email = "julia.wiel@nina.no",
    path = "https://orcid.org/0009-0009-7224-3953",
    role = "contributor",
    organization = "Norwegian Institute for Nature Research (NINA)"
  ),
  list(
    title = "Benjamin Cretois",
    email = "benjamin.cretois@nina.no",
    path = "https://orcid.org/0000-0001-8668-3321",
    role = "rightsHolder",
    organization = "Norwegian Institute for Nature Research (NINA)"
  ),
  list(
    title = "Carolyn Rosten",
    email = "carolyn.rosten@nina.no",
    path = "https://orcid.org/0000-0002-1117-444X",
    role = "rightsHolder",
    organization = "Norwegian Institute for Nature Research (NINA)"
  ),
  list(
    title = "Sarab Sethi",
    email = "sarab.sethi@imperial.ac.uk",
    path = "https://orcid.org/0000-0002-5939-0432",
    role = "principalInvestigator",
    organization = "Imperial College London"
  ),
  list(
    title = "I. Avery Bick",
    email = "i.avery.bick@gmail.com",
    path = "https://orcid.org/0000-0002-8007-9649",
    role = "principalInvestigator",
    organization = "Norwegian Institute for Nature Research (NINA)"
  )
)

acoustic$licenses <- list(
  list(
    name = "CC0-1.0",
    scope = "data" # Required
  ),
  list(
    path = "http://creativecommons.org/licenses/by/4.0/",
    scope = "media" # Required
  )
)

acoustic$project <- list( # Required
  id = NULL,
  title = "The Sound of Norway", # Required
  acronym = NULL,
  description = "The Sound of Norway project monitors ecosystems across the nation with real- time recording devices. Using machine learning to automatically classify bird vocalisations, we can simultaneously track the distribution and migration patterns of many species on vast scales and over long time-periods.",
  protocolType = "Passive Acoustic Monitoring",
  samplingDesign = "systematic random", # Required
  path = "https://thesoundofnorway.com/",
  captureMethod = "continous", # Required
  individualAnimals = FALSE, # Required
  observationLevel = "media" # Required
)
```

## Create taxonomy

```{r}
map_taxonomy <- function(taxonomy) {
  list(
    scientificName = taxonomy$ScientificName,
    vernacularNames = list(
      eng = taxonomy$EnglishName
      # nor = taxonomy$NorwegianName #gives error in read_camtrapdp() | lexical error: invalid bytes in UTF8 string
      )
  )
}
```

```{r}
taxonomy_list <- apply(taxonomy, 1, as.list)
acoustic$taxonomic <- purrr::map(taxonomy_list, map_taxonomy)
```


# Write Data Package

```{r}
frictionless::write_package(acoustic, here::here("data", "processed", "birdnet", "frictionless"))
```

# Read with camtrapdp

This automatically updates the spatial, temporal and taxonomic coverage in the metadata, based on the data.

```{r}
acoustic_dp <- read_camtrapdp(here::here("data", "processed", "birdnet", "frictionless", "datapackage.json"))
```
# Write Camtrap DP
```{r}
write_camtrapdp(acoustic_dp, here::here("data", "processed", "birdnet", "camtrapdp"))
```
